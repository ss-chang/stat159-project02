y_train,
alpha = 1, # LASSO parameter
lambda = grid <- 10^seq(10, -2, length = 100),
nfolds = 10, # performs 10-fold cross validation
standardize = F, # we already standardize our data
intercept = F)
# select best model
lasso_best_model <- lasso_fit$lambda.min
# plot tuning parameter
plot(lasso_fit)
# coefficients of our fit
coef(lasso_fit)
# compute mean square error
lasso_predictions <- predict(lasso_fit, x_test, s = lasso_best_model
lasso_mse <- mean((y_test - predictions)^2)
# official fit on full dataset
full_data_lasso_fit <- glmnet(x,
y,
alpha=1, #LASSO
lambda = best_lambda,
standardize = F,
intercept = F)
coef(full_data_lasso_fit)
# save official fit as .RDdata
save(lasso_fit,
lasso_best_model,
lasso_predictions,
lasso_mse,
full_data_lasso_fit, file = "../../data/fit-lasso.RData")
lasso_predictions <- predict(lasso_fit, x_test, s = lasso_best_model
lasso_predictions <- predict(lasso_fit, x_test, s = lasso_best_model)
lasso_predictions <- predict(lasso_fit, x_test, s = lasso_best_model)
# ==============================================================================
# title: regression-lasso.R
# author: Nura Kawa
#
# summary:
# + fit a LASSO model to standardized credit dataset
# + make predictions using training/testing sets
# + fit model on full data
# ==============================================================================
# load data
library(glmnet)
# load training-testing data
load("../../data/train-test.RData")
# fit the LASSO model
lasso_fit <- cv.glmnet(x_train,
y_train,
alpha = 1, # LASSO parameter
lambda = grid <- 10^seq(10, -2, length = 100),
nfolds = 10, # performs 10-fold cross validation
standardize = F, # we already standardize our data
intercept = F)
# select best model
lasso_best_model <- lasso_fit$lambda.min
# plot tuning parameter
plot(lasso_fit)
# coefficients of our fit
coef(lasso_fit)
# compute mean square error
lasso_predictions <- predict(lasso_fit, x_test, s = lasso_best_model)
lasso_mse <- mean((y_test - predictions)^2)
# official fit on full dataset
full_data_lasso_fit <- glmnet(x,
y,
alpha=1, #LASSO
lambda = best_lambda,
standardize = F,
intercept = F)
coef(full_data_lasso_fit)
# save official fit as .RDdata
save(lasso_fit,
lasso_best_model,
lasso_predictions,
lasso_mse,
full_data_lasso_fit, file = "../../data/fit-lasso.RData")
coef(full_data_lasso_fit)
full_data_lasso_fit <- glmnet(x,
y,
alpha=1, #LASSO
lambda = best_lambda,
standardize = F,
intercept = F)
# official fit on full dataset
full_data_lasso_fit <- glmnet(x,
y,
alpha=1, #LASSO
lambda = lasso_best_model,
standardize = F,
intercept = F)
coef(full_data_lasso_fit)
# save official fit as .RDdata
save(lasso_fit,
lasso_best_model,
lasso_predictions,
lasso_mse,
full_data_lasso_fit, file = "../../data/fit-lasso.RData")
lasso_fit <- cv.glmnet(x_train,
y_train,
alpha = 1, # LASSO parameter
lambda = grid <- 10^seq(10, -2, length = 100),
nfolds = 10, # performs 10-fold cross validation
standardize = F, # we already standardize our data
intercept = F)
save(ols_fit,
ols_fit_sum,
ols_mse,
full_data_ols_fit,
file = "../../data/regression/fit-ols.RData")
# load data
library(glmnet)
# load training-testing data
load("../../data/train-test.RData")
# fit the LASSO model
lasso_fit <- cv.glmnet(x_train,
y_train,
alpha = 1, # LASSO parameter
lambda = grid <- 10^seq(10, -2, length = 100),
nfolds = 10, # performs 10-fold cross validation
standardize = F, # we already standardize our data
intercept = F)
# select best model
lasso_best_model <- lasso_fit$lambda.min
# plot tuning parameter
plot(lasso_fit)
# coefficients of our fit
coef(lasso_fit)
# compute mean square error
lasso_predictions <- predict(lasso_fit, x_test, s = lasso_best_model)
lasso_mse <- mean((y_test - lasso_predictions)^2)
# official fit on full dataset
full_data_lasso_fit <- glmnet(x,
y,
alpha=1, #LASSO
lambda = lasso_best_model,
standardize = F,
intercept = F)
coef(full_data_lasso_fit)
# save official fit as .RDdata
save(lasso_fit,
lasso_best_model,
lasso_predictions,
lasso_mse,
full_data_lasso_fit, file = "../../data/fit-lasso.RData")
library(pls)
load("../../data/train-test.RData")
# ==============================================================================
# Perform 10-fold cross-validation on train set
# ==============================================================================
pcr_fit <- pcr(y_train~x_train,
validation = "CV")
# ==============================================================================
# Select the best model
# ==============================================================================
pcr_best_model <- pcr_fit$validation$PRESS
# ==============================================================================
# Produce visualization of which parameter gives the "best" model
# ==============================================================================
validationplot(pcr_fit, val.type = "MSEP")
coef(pcr_fit)
# ==============================================================================
# Compute mean square error for the test set
# ==============================================================================
pcr_predictions <- predict(pcr_fit, x_test, s = pcr_best_model)
pcr_mse <- mean((y_test - pcr_predictions)^2)
# ==============================================================================
# Refit the ridge regression on the full data set
# ==============================================================================
# official fit on full dataset
full_data_pcr_fit <- pcr(y~x,
validation = "CV")
coef(full_data_pcr_fit)
# ==============================================================================
# Save relevant objects in fit-pcr.RData
# ==============================================================================
save(pcr_fit,
pcr_best_lambda,
pcr_predictions,
pcr_mse,
full_data_pcr_fit,
file = "../../data/regression/fit-pcr.RData")
# load data
library(pls)
# load training-testing data
load("../../data/train-test.RData")
# pls_fit the PLS model
pls_fit <- plsr(y_train ~ x_train,
scale = FALSE,
validation = "CV")
# select best model
pls_best_model <- which.min(pls_fit$validation$PRESS) #best number of components
# plot tuning parameter
validationplot(pls_fit, val.type = "MSEP")
# coefficients of our pls_fit
coef(pls_fit)
# compute mean square error
pls_predictions <- predict(pls_fit, x_test, s = pls_best_model)
pls_mse <- mean((y_test - pls_predictions)^2)
# official pls_fit on full dataset
full_data_pls_fit <- plsr(y ~ x,
scale = FALSE,
validation = "CV",
ncomp = pls_best_model)
coef(full_data_pls_fit)
# save official pls_fit as .RDdata
save(pls_fit,
pls_best_model,
pls_predictions,
pls_mse,
full_data_pls_fit,
file = "../../data/regression/fit-pls.RData")
# ==============================================================================
# title: regression-ols.R
# author: Shannon Chang
#
# summary:
# + fit an Ordinary Least Squares model to standardized credit dataset
# + make predictions using training/testing sets
# + fit model on full data
# ==============================================================================
# ==============================================================================
# Load training and testing data
# ==============================================================================
load("../../data/train-test.RData")
# ==============================================================================
# Fit ordinary least squares regression
# ==============================================================================
ols_fit <- lm(y_train~x_train)
# ==============================================================================
# Compute mean square error for the test set
# ==============================================================================
ols_fit_sum <- summary(ols_fit)
ols_mse <- mean(ols_fit_sum$residuals^2)
# ==============================================================================
# Refit the OLS regression on the full data set
# ==============================================================================
# official fit on full dataset
full_data_ols_fit <- lm(y~x)
coef(full_data_ols_fit)
# ==============================================================================
# Save relevant objects in fit-ols.RData
# ==============================================================================
save(ols_fit,
ols_fit_sum,
ols_mse,
full_data_ols_fit,
file = "../../data/regression/fit-ols.RData")
# ==============================================================================
# title: regression-lasso.R
# author: Nura Kawa
#
# summary:
# + fit a LASSO model to standardized credit dataset
# + make predictions using training/testing sets
# + fit model on full data
# ==============================================================================
# load data
library(glmnet)
# load training-testing data
load("../../data/train-test.RData")
# fit the LASSO model
lasso_fit <- cv.glmnet(x_train,
y_train,
alpha = 1, # LASSO parameter
lambda = grid <- 10^seq(10, -2, length = 100),
nfolds = 10, # performs 10-fold cross validation
standardize = F, # we already standardize our data
intercept = F)
# select best model
lasso_best_model <- lasso_fit$lambda.min
# plot tuning parameter
plot(lasso_fit)
# coefficients of our fit
coef(lasso_fit)
# compute mean square error
lasso_predictions <- predict(lasso_fit, x_test, s = lasso_best_model)
lasso_mse <- mean((y_test - lasso_predictions)^2)
# official fit on full dataset
full_data_lasso_fit <- glmnet(x,
y,
alpha=1, #LASSO
lambda = lasso_best_model,
standardize = F,
intercept = F)
coef(full_data_lasso_fit)
# save official fit as .RDdata
save(lasso_fit,
lasso_best_model,
lasso_predictions,
lasso_mse,
full_data_lasso_fit, file = "../../data/fit-lasso.RData")
full_data_pcr_fit <- pcr(y~x,
validation = "CV")
# ==============================================================================
# title: regression-pcr.R
# author: Shannon Chang
#
# summary:
# + fit a Principal Components Regression model to standardized credit dataset
# + make predictions using training/testing sets
# + fit model on full data
# ==============================================================================
# ==============================================================================
# Load relevant package and training and testing data
# ==============================================================================
library(pls)
load("../../data/train-test.RData")
# ==============================================================================
# Perform 10-fold cross-validation on train set
# ==============================================================================
pcr_fit <- pcr(y_train~x_train,
validation = "CV")
# ==============================================================================
# Select the best model
# ==============================================================================
pcr_best_model <- pcr_fit$validation$PRESS
# ==============================================================================
# Produce visualization of which parameter gives the "best" model
# ==============================================================================
validationplot(pcr_fit, val.type = "MSEP")
coef(pcr_fit)
# ==============================================================================
# Compute mean square error for the test set
# ==============================================================================
pcr_predictions <- predict(pcr_fit, x_test, s = pcr_best_model)
pcr_mse <- mean((y_test - pcr_predictions)^2)
# ==============================================================================
# Refit the ridge regression on the full data set
# ==============================================================================
# official fit on full dataset
full_data_pcr_fit <- pcr(y~x,
validation = "CV")
coef(full_data_pcr_fit)
# ==============================================================================
# Save relevant objects in fit-pcr.RData
# ==============================================================================
save(pcr_fit,
pcr_best_lambda,
pcr_predictions,
pcr_mse,
full_data_pcr_fit,
file = "../../data/regression/fit-pcr.RData")
# ==============================================================================
# title: regression-pcr.R
# author: Shannon Chang
#
# summary:
# + fit a Principal Components Regression model to standardized credit dataset
# + make predictions using training/testing sets
# + fit model on full data
# ==============================================================================
# ==============================================================================
# Load relevant package and training and testing data
# ==============================================================================
library(pls)
load("../../data/train-test.RData")
# ==============================================================================
# Perform 10-fold cross-validation on train set
# ==============================================================================
pcr_fit <- pcr(y_train~x_train,
scale = FALSE,
validation = "CV")
# ==============================================================================
# Select the best model
# ==============================================================================
pcr_best_model <- pcr_fit$validation$PRESS
# ==============================================================================
# Produce visualization of which parameter gives the "best" model
# ==============================================================================
validationplot(pcr_fit, val.type = "MSEP")
coef(pcr_fit)
# ==============================================================================
# Compute mean square error for the test set
# ==============================================================================
pcr_predictions <- predict(pcr_fit, x_test, s = pcr_best_model)
pcr_mse <- mean((y_test - pcr_predictions)^2)
# ==============================================================================
# Refit the ridge regression on the full data set
# ==============================================================================
# official fit on full dataset
full_data_pcr_fit <- pcr(y~x,
validation = "CV")
coef(full_data_pcr_fit)
# ==============================================================================
# Save relevant objects in fit-pcr.RData
# ==============================================================================
save(pcr_fit,
pcr_best_lambda,
pcr_predictions,
pcr_mse,
full_data_pcr_fit,
file = "../../data/regression/fit-pcr.RData")
# load data
library(pls)
# load training-testing data
load("../../data/train-test.RData")
# pls_fit the PLS model
pls_fit <- plsr(y_train ~ x_train,
scale = FALSE,
validation = "CV")
# select best model
pls_best_model <- which.min(pls_fit$validation$PRESS) #best number of components
# plot tuning parameter
validationplot(pls_fit, val.type = "MSEP")
# coefficients of our pls_fit
coef(pls_fit)
# compute mean square error
pls_predictions <- predict(pls_fit, x_test, s = pls_best_model)
pls_mse <- mean((y_test - pls_predictions)^2)
# official pls_fit on full dataset
full_data_pls_fit <- plsr(y ~ x,
scale = FALSE,
validation = "CV",
ncomp = pls_best_model)
coef(full_data_pls_fit)
# save official pls_fit as .RDdata
save(pls_fit,
pls_best_model,
pls_predictions,
pls_mse,
full_data_pls_fit,
file = "../../data/regression/fit-pls.RData")
# ==============================================================================
# Load relevant package and training and testing data
# ==============================================================================
library(glmnet)
load("../../data/train-test.RData")
# ==============================================================================
# Perform 10-fold cross-validation on train set
# ==============================================================================
ridge_fit <- cv.glmnet(x_train,
y_train,
alpha = 0, # ridge parameter
lambda = grid <- 10^seq(10, -2, length = 100),
nfolds = 10, # performs 10-fold cross validation
standardize = FALSE, # we already standardized our data
intercept = FALSE)
# ==============================================================================
# Select the best model
# ==============================================================================
ridge_best_model <- ridge_fit$lambda.min
# ==============================================================================
# Produce visualization of which parameter gives the "best" model
# ==============================================================================
# plot tuning parameter
plot(ridge_fit)
# coefficients of our fit
coef(ridge_fit)
# ==============================================================================
# Compute mean square error for the test set
# ==============================================================================
# compute mean square error
ridge_predictions <- predict(ridge_fit, x_test, s = ridge_best_model)
ridge_mse <- mean((y_test - ridge_predictions)^2)
# ==============================================================================
# Refit the ridge regression on the full data set
# ==============================================================================
# official fit on full dataset
full_data_ridge_fit <- glmnet(x,
y,
alpha = 0, # ridge parameter
lambda = ridge_best_model,
standardize = FALSE,
intercept = FALSE)
coef(full_data_ridge_fit)
# ==============================================================================
# Save relevant objects in fit-ridge.RData
# ==============================================================================
save(ridge_fit,
ridge_best_model,
ridge_predictions,
ridge_mse,
full_data_ridge_fit,
file = "../../data/regression/ridge-fit.RData")
ols_mse <- mean(summary(lm(y_test~x_test)$residuals^2)
ols_mse <- mean(summary(lm(y_test~x_test)$residuals^2))
# ==============================================================================
# title: regression-ols.R
# author: Shannon Chang
#
# summary:
# + fit an Ordinary Least Squares model to standardized credit dataset
# + make predictions using training/testing sets
# + fit model on full data
# ==============================================================================
# ==============================================================================
# Load training and testing data
# ==============================================================================
load("../../data/train-test.RData")
# ==============================================================================
# Fit ordinary least squares regression
# ==============================================================================
ols_fit <- lm(y_train~x_train)
ols_fit_sum <- summary(ols_fit)
# ==============================================================================
# Compute mean square error for the test set
# ==============================================================================
ols_mse <- mean(summary(lm(y_test~x_test)$residuals^2))
# ==============================================================================
# Refit the OLS regression on the full data set
# ==============================================================================
# official fit on full dataset
full_data_ols_fit <- lm(y~x)
coef(full_data_ols_fit)
# ==============================================================================
# Save relevant objects in fit-ols.RData
# ==============================================================================
save(ols_fit,
ols_fit_sum,
ols_mse,
full_data_ols_fit,
file = "../../data/regression/fit-ols.RData")
